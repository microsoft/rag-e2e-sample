{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2469417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import openai\n",
    "from dotenv import dotenv_values\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "sys.path.append(\"..\") ## add directory above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af107d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"../llm.env\" # change to use your own .env file\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "# os.environ[\"OPENAI_API_TYPE\"] = config[\"OPENAI_API_TYPE\"] #\"azure\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = config['OPENAI_API_KEY']\n",
    "# os.environ[\"OPENAI_API_BASE\"] = config['OPENAI_API_BASE']\n",
    "# os.environ[\"OPENAI_API_VERSION\"] = config['OPENAI_API_VERSION']\n",
    "\n",
    "#Azure OpenAI\n",
    "openai.api_type = config[\"OPENAI_API_TYPE\"] #\"azure\"\n",
    "openai.api_key = config['OPENAI_API_KEY']\n",
    "openai.api_base = config['OPENAI_API_BASE']\n",
    "openai.api_version = config['OPENAI_API_VERSION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9c886c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = \"gpt-4-32k\"\n",
    "#engine = \"gpt-35-turbo\"\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=engine,\n",
    "    openai_api_base=openai.api_base,\n",
    "    openai_api_version=openai.api_version,\n",
    "    openai_api_key=openai.api_key,\n",
    "    openai_api_type = openai.api_type,\n",
    "    temperature=0.0, verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b0e6f8",
   "metadata": {},
   "source": [
    "## 1. Demonstrating conversation summary memory chain:\n",
    "This chain summarizes the previous user conversation and appends the summary to context for answering questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4886138d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: \n",
      "USSA is a space agency in county Y. It is a government agency responsible for the exploration and development of space.\n",
      "Question 2: \n",
      "Yes, I mentioned earlier about the USSA, which is a space agency in county Y, responsible for space exploration and development.\n",
      "\n",
      "Context in question 2 does not contain any specific information regarding the \n",
      "       user question but still llm provides correct answer by using the memory of previous conversation\n"
     ]
    }
   ],
   "source": [
    "from chatbot_features import qa_chain_ConversationSummaryMemory\n",
    "\n",
    "# Make a Quesion Answer chain function and pass \n",
    "prefix_template = \"\"\"\n",
    "        You are a chatbot having a conversation with a human. \n",
    "        Given the Context, Chat History, and a Human Query, \n",
    "        create a final answer. Don't hallucinate at all. If you don't have an answer, say \"I don't know\". \"\"\"\n",
    "\n",
    "qa_chain = qa_chain_ConversationSummaryMemory(llm, prefix_template = prefix_template, to_debug = False)\n",
    "\n",
    "## Question Answering\n",
    "\n",
    "#Question 1\n",
    "answer = qa_chain.run({\n",
    "'context': \"USSA is a space agency in county Y. It is a government agency responsible for the exploration and development of space.\",\n",
    "'human_input': \"What is USSA\" \n",
    "})\n",
    "\n",
    "print(\"Question 1: \")\n",
    "print(answer)\n",
    "\n",
    "# Question 2: \n",
    "answer = qa_chain.run({\n",
    "'context': \"Zootopia is a 2016 American computer-animated buddy cop action comedy film produced by Walt Disney Animation Studios.\",\n",
    "'human_input': \"Do you know about any space agency?\" \n",
    "}) \n",
    "\n",
    "print(\"Question 2: \")\n",
    "print(answer)\n",
    "print()\n",
    "print (\"\"\"Context in question 2 does not contain any specific information regarding the \n",
    "       user question but still llm provides correct answer by using the memory of previous conversation\"\"\")\n",
    "\n",
    "# print(qa_chain.memory) ## You can see the memory using this call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af592da",
   "metadata": {},
   "source": [
    "## 2. Demonstrating conversation buffer memory chain:\n",
    "This chain summarizes the previous user conversation and appends the summary to context for answering questions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69704b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: \n",
      "USSA is a space agency in county Y. It is a government agency responsible for the exploration and development of space.\n",
      "Question 2: \n",
      "Yes, I do. One example is the USSA, a space agency in county Y. It is a government agency responsible for the exploration and development of space.\n",
      "\n",
      "Context in question 2 does not contain any specific information regarding the \n",
      "       user question but still llm provides correct answer by using the memory of previous conversation\n"
     ]
    }
   ],
   "source": [
    "from chatbot_features import qa_chain_ConversationBufferMemory\n",
    "\n",
    "# Make a Quesion Answer chain function and pass \n",
    "prefix_template = \"\"\"\n",
    "        You are a chatbot having a conversation with a human. \n",
    "        Given the Context, Chat History, and a Human Query, \n",
    "        create a final answer. Don't hallucinate at all. If you don't have an answer, say \"I don't know\". \"\"\"\n",
    "\n",
    "qa_chain = qa_chain_ConversationBufferMemory(llm, prefix_template = prefix_template, to_debug = False)\n",
    "\n",
    "## Question Answering\n",
    "\n",
    "#Question 1\n",
    "answer = qa_chain.run({\n",
    "'context': \"USSA is a space agency in county Y. It is a government agency responsible for the exploration and development of space.\",\n",
    "'human_input': \"What is USSA\" \n",
    "})\n",
    "\n",
    "print(\"Question 1: \")\n",
    "print(answer)\n",
    "\n",
    "# Question 2: \n",
    "answer = qa_chain.run({\n",
    "'context': \"Zootopia is a 2016 American computer-animated buddy cop action comedy film produced by Walt Disney Animation Studios.\",\n",
    "'human_input': \"Do you know about any space agency?\" \n",
    "}) \n",
    "\n",
    "print(\"Question 2: \")\n",
    "print(answer)\n",
    "print()\n",
    "print (\"\"\"Context in question 2 does not contain any specific information regarding the \n",
    "       user question but still llm provides correct answer by using the memory of previous conversation\"\"\")\n",
    "\n",
    "# print(qa_chain.memory) ## You can see the memory using this call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542530f",
   "metadata": {},
   "source": [
    "## 3. Demonstrating usre query based context summarization chain:\n",
    "Sometimes context can be large and don't fit in a prompt window. So, this chain summarizes context given user query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539bc2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: \n",
      "USSA is a government space agency in county Y, responsible for the exploration and development of space.\n",
      "\n",
      "This llm extracts only relevant information from the context. \n"
     ]
    }
   ],
   "source": [
    "from chatbot_features import user_query_based_context_summarization\n",
    "\n",
    "# Template \n",
    "prefix_template = \"\"\"\n",
    "        Write a concise summary of the context so that it includes the details related to the human query. \"\"\"\n",
    "\n",
    "context_summary_chain = user_query_based_context_summarization(llm, prefix_template = prefix_template, to_debug = False)\n",
    "\n",
    "context = \"\"\"\n",
    "            USSA is a space agency in county Y. It is a government agency responsible\n",
    "            for the exploration and development of space.\n",
    "            Zootopia is a 2016 American computer-animated buddy cop action comedy\n",
    "            film produced by Walt Disney Animation Studios.\n",
    "            \"\"\"\n",
    "\n",
    "#Question 1\n",
    "answer = context_summary_chain.run({\n",
    "'context': context,\n",
    "'human_input': \"What is USSA?\" \n",
    "})\n",
    "\n",
    "\n",
    "print(\"Question 1: \")\n",
    "print(answer)\n",
    "print()\n",
    "\n",
    "print (\"\"\"This llm extracts only relevant information from the context. \"\"\")\n",
    "\n",
    "# print(qa_chain.memory) ## You can see the memory using this call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05f869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "nanogpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
