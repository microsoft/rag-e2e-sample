{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk Embedding using azure open ai   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables and keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "# specify the name of the .env file name \n",
    "env_name = \"llm_pgvector.env\" # change to your own .env file name\n",
    "config = dotenv_values(env_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the chunks and create embedding\n",
    "In this section, we will load the data into a pandas dataframe, use select columns, and create vector embedding using azure open ai. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "openai.api_type = config[\"OPENAI_API_TYPE\"] \n",
    "openai.api_key = config[\"OPENAI_API_KEY\"]\n",
    "openai.api_base = config[\"OPENAI_API_BASE\"] \n",
    "openai.api_version = config[\"OPENAI_API_VERSION\"] \n",
    "\n",
    "\n",
    "def createEmbeddings(text):\n",
    "    response = openai.Embedding.create(input=text , engine=config[\"OPENAI_DEPLOYMENT_EMBEDDING\"])\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "\n",
    "# Read data into a DataFrame\n",
    "df = pd.read_csv('../AnalyzedPDF/CombinedResults/Chunks.csv')\n",
    "\n",
    "\n",
    "# Create a new column called 'embedding' in the DataFrame\n",
    "df['Embedding'] = np.empty((len(df),), dtype=object)\n",
    "\n",
    "# Iterate over each row in the DataFrame and assign the concatenation and embeddings\n",
    "for index, row in df.iterrows():\n",
    "    text = row['Chunk']\n",
    "    \n",
    "    # Concatenate the desired columns\n",
    "    concat_text = f\"{text}\"\n",
    "    \n",
    "    # Create embeddings using the provided function\n",
    "    embeddings = createEmbeddings(concat_text)\n",
    "    #print(embeddings)\n",
    "    \n",
    "    # Assign the embeddings to the 'embedding' column\n",
    "    df.at[index, 'Embedding'] = embeddings\n",
    "    time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will rename the column names and add a new column as primary index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the DataFrame with 'Id' as the first column after index\n",
    "df.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code to save the embeddings and processed data for future use or skip the previous part of the code and and load the processed data to save into the db. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save CSV for future use. \n",
    "df.to_csv('../AnalyzedPDF/CombinedResults/ChunksEmbedding.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
