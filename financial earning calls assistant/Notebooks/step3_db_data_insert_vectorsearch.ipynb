{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Postgres Flex with vector search\n",
    "This sample shows how to use azure postgres (Flex) native vector search capabilities for RAG applications.  \n",
    "### Prerequisite: install python libraries\n",
    "- Please make sure all the libraries found in requirements.txt are installed in your python environment. \n",
    "- Rename example.env to llm.env and enter your credentials in llm_flex.env\n",
    "- Whitelist your IP to access your PostGres dv. Add you IP in \"Networking\" section of your PostGRes resource on the [Azure Portal](https://ms.portal.azure.com/)\n",
    "- To apply vector search, please install vector extensions for your db. You may follow this [link](https://learn.microsoft.com/en-us/azure/postgresql/flexible-server/concepts-extensions) to add vector to the allow-list of your db extensions.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load environment variables and keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "# specify the name of the .env file name \n",
    "env_name = \"llm_pgvector.env\" # change to your own .env file name\n",
    "config = dotenv_values(env_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Flex Postgres (PG) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import pool\n",
    "\n",
    "host = config[\"HOST\"]\n",
    "dbname = config[\"DBNAME\"] \n",
    "user = config[\"USER\"] \n",
    "password = config[\"PASSWORD\"] \n",
    "sslmode = config[\"SSLMODE\"] \n",
    "\n",
    "# Build a connection string from the variables\n",
    "conn_string = \"host={0} user={1} dbname={2} password={3} sslmode={4}\".format(host, user, dbname, password, sslmode)\n",
    "\n",
    "postgreSQL_pool = psycopg2.pool.SimpleConnectionPool(1, 20,conn_string)\n",
    "if (postgreSQL_pool):\n",
    "    print(\"Connection pool created successfully\")\n",
    "\n",
    "# Use getconn() to get a connection from the connection pool\n",
    "connection = postgreSQL_pool.getconn()\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use pgvector, we need to first create the vector extension as described in this [link](https://learn.microsoft.com/en-us/azure/postgresql/flexible-server/how-to-use-pgvector) and shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a cursor to perform database operations\n",
    "# This is likely in case extension isn't already created from portal.\n",
    "cursor = connection.cursor()\n",
    "\n",
    "try:\n",
    "    # Start a new transaction\n",
    "    cursor.execute(\"BEGIN;\")\n",
    "\n",
    "    # Previous transaction statements\n",
    "    # ...\n",
    "\n",
    "    # Check if the extension already exists\n",
    "    extension_query = \"SELECT * FROM pg_extension WHERE extname = 'vector';\"\n",
    "    cursor.execute(extension_query)\n",
    "    extension_exists = cursor.fetchone()\n",
    "\n",
    "    if not extension_exists:\n",
    "        # Extension does not exist, create it\n",
    "        create_extension_query = \"CREATE EXTENSION vector;\"\n",
    "        cursor.execute(create_extension_query)\n",
    "        connection.commit()\n",
    "    else:\n",
    "        # Extension already exists, pass through\n",
    "        pass\n",
    "\n",
    "    # Commit the transaction\n",
    "    cursor.execute(\"COMMIT;\")\n",
    "except Exception as e:\n",
    "    # An error occurred, rollback the transaction\n",
    "    cursor.execute(\"ROLLBACK;\")\n",
    "    raise e\n",
    "finally:\n",
    "    # Close the cursor\n",
    "    cursor.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will list the existing extensions for your db. Please make sure ['VECTOR'] IS listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Establish a connection to the database\n",
    "connection = psycopg2.connect(conn_string)\n",
    "\n",
    "# Open a cursor to perform database operations\n",
    "cursor = connection.cursor()\n",
    "\n",
    "\n",
    "\n",
    "# Define the SHOW EXTENSIONS query\n",
    "show_extensions_query = \"SHOW azure.extensions;\"\n",
    "\n",
    "# Execute the SHOW EXTENSIONS query\n",
    "cursor.execute(show_extensions_query)\n",
    "\n",
    "connection.commit()\n",
    "# Fetch and print the results\n",
    "results = cursor.fetchall()\n",
    "for row in results:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OPTIONAL] You may run the following to list the existing tables in your db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### to get list of existing tables in the database\n",
    "# Create a cursor object to interact with the database\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Execute the SQL query to retrieve the table names\n",
    "cursor.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\")\n",
    "\n",
    "# Fetch all the results\n",
    "table_names = cursor.fetchall()\n",
    "\n",
    "# Print the table names\n",
    "for table in table_names:\n",
    "    print(table[0])\n",
    "    \n",
    "if not table_names:\n",
    "    print(\"No table found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to drop a db, please uncomment the following code and define the table_name you wish to remove from your db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_name = 'abc_v0'\n",
    "# batch_size = 1000\n",
    "# # Drop previous table of same name if one exists\n",
    "# cursor.execute(f\"DROP TABLE IF EXISTS {table_name};\")\n",
    "# print(\"Finished dropping table (if existed)\")\n",
    "# connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into database\n",
    "In this section, we will store two tables into db 1) {filter_id1_name}: maps filter_id values to DocId 2)ChunkEmbeddings. Let's first load the data into data frames.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_chunks_embedding = pd.read_csv('../AnalyzedPDF/CombinedResults/ChunksEmbedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks_embedding.head(3)\n",
    "#columns should look like the following with order preserved\n",
    "#Id, Chunk, PageNumber, LineNumber, DocId, Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store embeddings dataframe into a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgvector.psycopg2 import register_vector\n",
    "from psycopg2 import Error\n",
    "from psycopg2 import sql\n",
    "import numpy as np\n",
    "# Establish a connection to the database\n",
    "connection = psycopg2.connect(conn_string)\n",
    "\n",
    "# Register 'pgvector' type for the 'embedding' column\n",
    "register_vector(connection)\n",
    "\n",
    "# Convert the DataFrame to a list of tuples for bulk insertion\n",
    "records = df_chunks_embedding.to_records(index=False)\n",
    "records_list = records.tolist()\n",
    "\n",
    "# Open a cursor to perform database operations\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Define the table name\n",
    "table_name = 'EarningsCallChunksEmbedding'\n",
    "batch_size = 100\n",
    "# Drop previous table of same name if one exists\n",
    "cursor.execute(f\"DROP TABLE IF EXISTS {table_name};\")\n",
    "print(\"Finished dropping table (if existed)\")\n",
    "connection.commit()\n",
    "\n",
    "# Execute the query to check if the table exists\n",
    "cursor.execute(f\"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = '{table_name}');\")\n",
    "\n",
    "# Fetch the result\n",
    "exists = cursor.fetchone()[0]\n",
    "\n",
    "if exists:\n",
    "    print(f\"The table '{table_name}' exists in the database.\")\n",
    "    print(\"You may drop previous table (see commented code above) if you want to re-insert data.\")\n",
    "else:\n",
    "    print(f\"The table '{table_name}' does not exist in the database. Creating it now and inserting data ...\")\n",
    "    # Build a connection string from the variables\n",
    "    conn_string = \"host={0} user={1} dbname={2} password={3} sslmode={4}\".format(host, user, dbname, password, sslmode)\n",
    "\n",
    "    postgreSQL_pool = psycopg2.pool.SimpleConnectionPool(1, 20, conn_string)\n",
    "    if postgreSQL_pool:\n",
    "        print(\"Connection pool created successfully\")\n",
    "\n",
    "    # Use getconn() to get a connection from the connection pool\n",
    "    with postgreSQL_pool.getconn() as connection:\n",
    "        # Define the CREATE TABLE query\n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            Id INTEGER PRIMARY KEY,\n",
    "            Ticker TEXT,\n",
    "            Year INTEGER,\n",
    "            Quarter INTEGER,\n",
    "            Chunk TEXT,\n",
    "            PageNumber INTEGER,\n",
    "            LineNumber INTEGER,\n",
    "            Embedding VECTOR\n",
    "        );\n",
    "        \"\"\"\n",
    "        # Execute the CREATE TABLE query\n",
    "        cursor.execute(create_table_query)\n",
    "        connection.commit()\n",
    "\n",
    "        # Define the INSERT INTO query\n",
    "        insert_query = f\"INSERT INTO {table_name} (Id, Ticker, Year, Quarter, Chunk, PageNumber, LineNumber, Embedding) \" \\\n",
    "                    f\"VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        # Execute the INSERT INTO query for each row\n",
    "        cursor.executemany(insert_query, records_list)\n",
    "        connection.commit()\n",
    "        \n",
    "        # Execute the CREATE TABLE query\n",
    "        try:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(create_table_query)\n",
    "                connection.commit()\n",
    "                print(f\"Table {table_name} created successfully!\")\n",
    "        except (Exception, Error) as e:\n",
    "            print(f\"Error creating table {table_name}: {e}\")\n",
    "            connection.rollback()        \n",
    "        \n",
    "        \n",
    "        # Convert numpy.int32 to int in each row\n",
    "        records_list = [\n",
    "            tuple(int(value) if isinstance(value, np.int32) else value for value in record)\n",
    "            for record in records_list\n",
    "        ]\n",
    "\n",
    "        # Split the records list into batches\n",
    "        batches = [records_list[i: i + batch_size] for i in range(0, len(records_list), batch_size)]\n",
    "\n",
    "        # Iterate over each batch and perform bulk insert\n",
    "        count = 0\n",
    "        for batch in batches:\n",
    "            count += 1\n",
    "            print(f\"Inserting batch {count} into the table\")\n",
    "            try:\n",
    "                insert_query = sql.SQL(f\"INSERT INTO {table_name} (Id, Ticker, Year, Quarter, Chunk, PageNumber, LineNumber, Embedding) \" \\\n",
    "                                    f\"VALUES ({', '.join(['%s'] * len(batch[0]))})\")\n",
    "                \n",
    "                with connection.cursor() as cursor:\n",
    "                    cursor.executemany(insert_query, batch)\n",
    "                    connection.commit()\n",
    "            except (Exception, Error) as e:\n",
    "                print(f\"Error inserting batch into the table: {e}\")\n",
    "                connection.rollback()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already established a connection and have a cursor object\n",
    "\n",
    "# Rollback the current transaction\n",
    "connection.rollback()\n",
    "cursor = connection.cursor()\n",
    "# Execute the SELECT statement\n",
    "\n",
    "try:\n",
    "    cursor.execute(f\"SELECT count(Id) FROM {table_name};\")\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        print(f\"Number of items: {row}\")\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error executing SELECT statement: {e}\")\n",
    "    \n",
    "try:\n",
    "    cursor.execute(f\"SELECT embedding FROM {table_name} limit 5;\")\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        print(f\"Items ID: {row}\")\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error executing SELECT statement: {e}\")\n",
    "\n",
    "try:\n",
    "    cursor.execute(f\"SELECT Ticker FROM {table_name} limit 1;\")\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        print(f\"Items ID: {row}\")\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error executing SELECT statement: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Asks a Question \n",
    "In this step, the code will convert the user's question to an embedding and then retieve the top K document chunks based on the users' question using the similarity. Please note that other similarity metrics can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userQuestion = \"What was the highest earning?\"\n",
    "filter_col = \"Ticker\"\n",
    "filter_val = \"MSFT\"\n",
    "retrieve_k = 3 # for retrieving the top k reviews from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "openai.api_type = config[\"OPENAI_API_TYPE\"] \n",
    "openai.api_key = config[\"OPENAI_API_KEY\"]\n",
    "openai.api_base = config[\"OPENAI_API_BASE\"] \n",
    "openai.api_version = config[\"OPENAI_API_VERSION\"] \n",
    "\n",
    "\n",
    "def createEmbeddings(text):\n",
    "    response = openai.Embedding.create(input=text , engine=config[\"OPENAI_DEPLOYMENT_EMBEDDING\"])\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for the question and retrieve the top k document chunks\n",
    "questionEmbedding = createEmbeddings(userQuestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Search\n",
    "In this case, we will first filter based on id range, and then do similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "connection = psycopg2.connect(conn_string)\n",
    "# Create a cursor after the connection\n",
    "# Register 'pgvector' type for the 'embedding' column\n",
    "register_vector(connection)\n",
    "cursor = connection.cursor()\n",
    "select_query = f\"SELECT Id FROM {table_name}  WHERE {filter_col} = '{filter_val}' ORDER BY Embedding <-> %s LIMIT 3\"\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(select_query, (np.array(questionEmbedding),))\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the top k ids to retrieve the actual text from the database \n",
    "top_ids = []\n",
    "for i in range(len(results)):\n",
    "    top_ids.append(int(results[i][0]))\n",
    "\n",
    "print(top_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note how the top ids are now different and within range."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve text from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already established a connection and have a cursor object\n",
    "\n",
    "# Rollback the current transaction\n",
    "connection.rollback()\n",
    "\n",
    "format_ids = ', '.join(['%s'] * len(top_ids))\n",
    "\n",
    "sql = f\"SELECT CONCAT('PageNumber: ', PageNumber, ' ', 'Text: ', Chunk) AS concat FROM {table_name} WHERE id IN ({format_ids})\"\n",
    "\n",
    "# Execute the SELECT statement\n",
    "try:\n",
    "    cursor.execute(sql, top_ids)    \n",
    "    top_rows = cursor.fetchall()\n",
    "    for row in top_rows:\n",
    "        print(row)\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error executing SELECT statement: {e}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offer Response to User's Question\n",
    "In order to offer a response, a user can either follow a simple prompting method as shown below or leverage more sophisticated ways used by other libraries, such as [langchain](https://python.langchain.com/en/latest/index.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompting directly using Azure Open AI service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prompt template \n",
    "template = \"\"\"\n",
    "    context :{context}\n",
    "    Answer the question based on the context above. Provide the page number associated with the answer as reference as well. If the\n",
    "    information to answer the question is not present in the given context then reply \"I don't know\".\n",
    "    Question: {query}\n",
    "    Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the context from the top_rows\n",
    "context = \"\"\n",
    "for row in top_rows:\n",
    "    context += row[0]\n",
    "    context += \"\\n\"\n",
    "    \n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(userQuestion)\n",
    "prompt = template.format(context=context, query=userQuestion)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "    engine= config['OPENAI_DEPLOYMENT_COMPLETION'],\n",
    "    prompt=prompt,\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=1,\n",
    ")\n",
    "\n",
    "print(\"prompt: \", prompt)\n",
    "print('~~~~~')\n",
    "# print(\"response: \", response['choices'][0]['text'].replace('\\n', '').replace(' .', '.').strip())\n",
    "print(response['choices'][0]['text'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
