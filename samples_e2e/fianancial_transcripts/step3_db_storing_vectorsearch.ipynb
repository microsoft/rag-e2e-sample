{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store chunks into Vector Data Base using Azure Cognitive Search (ACS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import json  \n",
    "import openai  \n",
    "from dotenv import load_dotenv\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import Vector  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    "    SemanticConfiguration,  \n",
    "    PrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    SemanticSettings,  \n",
    "    VectorSearch,  \n",
    "    HnswVectorSearchAlgorithmConfiguration\n",
    ")\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load environment variables and keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "# specify the name of the .env file name \n",
    "env_name = \"../../llm.env\" # change to your own .env file name\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "# Azure OpenAI\n",
    "openai.api_type = config[\"OPENAI_API_TYPE\"] #\"azure\"\n",
    "openai.api_key = config['OPENAI_API_KEY']\n",
    "openai.api_base = config['OPENAI_API_BASE']\n",
    "openai.api_version = config['OPENAI_API_VERSION']\n",
    "\n",
    "## Cog Search\n",
    "cogsearch_name = config[\"COGSEARCH_NAME\"]\n",
    "index_name = config[\"COGSEARCH_INDEX_NAME\"]\n",
    "key = config[\"COGSEARCH_API_KEY\"]\n",
    "service_endpoint = \"https://\"+config[\"COGSEARCH_NAME\"] + \".search.windows.net\"\n",
    "\n",
    "credential = AzureKeyCredential(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEmbeddings(text):\n",
    "    response = openai.Embedding.create(input=text , engine=config[\"OPENAI_DEPLOYMENT_EMBEDDING\"])\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the embeddings in Azure Cognitive Search Vector Store\n",
    "\n",
    "[AzureCogSearch](https://learn.microsoft.com/en-us/azure/search/search-what-is-azure-search) provides a simple interface to create a vector database, store and retrieve data using vector search. You can read more about [here](https://github.com/Azure/cognitive-search-vector-pr/tree/main) more about Vector Search.\n",
    "\n",
    "There are two steps to store data in AzureCogSearch vector database:\n",
    "- First, we create the index (or schema) of the vector database\n",
    "- Second, we add the chunked documents and their embeddings to the vector datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks_embedding = pd.read_csv('AnalyzedPDF/ChunksEmbedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Chunk</th>\n",
       "      <th>PageNumber</th>\n",
       "      <th>LineNumber</th>\n",
       "      <th>Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Microsoft FY23 First Quarter Earnings Conferen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.022691456601023674, -0.028929658234119415,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>On the Microsoft Investor Relations website, y...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>[-0.022940216585993767, -0.008343684487044811,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>GAAP. They are included as additional clarifyi...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>[-0.01130777969956398, -0.0038822712376713753,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Ticker  Year  Quarter  \\\n",
       "0   1   MSFT    23        1   \n",
       "1   2   MSFT    23        1   \n",
       "2   3   MSFT    23        1   \n",
       "\n",
       "                                               Chunk  PageNumber  LineNumber  \\\n",
       "0  Microsoft FY23 First Quarter Earnings Conferen...           1           1   \n",
       "1  On the Microsoft Investor Relations website, y...           1           9   \n",
       "2  GAAP. They are included as additional clarifyi...           1          17   \n",
       "\n",
       "                                           Embedding  \n",
       "0  [-0.022691456601023674, -0.028929658234119415,...  \n",
       "1  [-0.022940216585993767, -0.008343684487044811,...  \n",
       "2  [-0.01130777969956398, -0.0038822712376713753,...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunks_embedding.head(3)\n",
    "#columns should look like the following with order preserved\n",
    "#Id, Chunk, PageNumber, LineNumber, DocId, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rag_prop_j_3 created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a search index\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=service_endpoint, credential=credential)\n",
    "fields = [\n",
    "    SimpleField(name=\"Id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"Ticker\", type=SearchFieldDataType.String, filterable=True),\n",
    "    SearchableField(name=\"Year\", type=SearchFieldDataType.String, filterable=True),\n",
    "    SearchableField(name=\"Quarter\", type=SearchFieldDataType.String, filterable=True),\n",
    "    SearchableField(name=\"Chunk\", type=SearchFieldDataType.String, searchable=True),\n",
    "    SearchableField(name=\"PageNumber\", type=SearchFieldDataType.String, filterable=True),\n",
    "    SearchableField(name=\"LineNumber\", type=SearchFieldDataType.String, filterable=True),\n",
    "    \n",
    "    SearchField(name=\"Embedding\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    algorithm_configurations=[\n",
    "        HnswVectorSearchAlgorithmConfiguration(\n",
    "            name=\"my-vector-config\",\n",
    "            kind=\"hnsw\",\n",
    "            parameters={\n",
    "                \"m\": 4,\n",
    "                \"efConstruction\": 400,\n",
    "                \"efSearch\": 500,\n",
    "                \"metric\": \"cosine\"\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"Ticker\"),\n",
    "#         prioritized_keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"Chunk\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_settings=semantic_settings)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 442 payload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Upload data to Index\n",
    "def batch_append_payload(df, search_client):\n",
    "    \"\"\"append payload for batch insertion (note: max 1000 rows per insertion) of embeddings to Cognitive Search\"\"\"\n",
    "    value_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        value_list.append(\n",
    "            {\n",
    "                \"Id\": str(index),\n",
    "                \"Ticker\": row[\"Ticker\"],\n",
    "                \"Year\": str(row[\"Year\"]),\n",
    "                \"Quarter\": str(row[\"Quarter\"]),\n",
    "                \"Chunk\": row[\"Chunk\"],\n",
    "                \"PageNumber\": str(row[\"PageNumber\"]),\n",
    "                \"LineNumber\": str(row[\"LineNumber\"]),\n",
    "                \"Embedding\": literal_eval(row['Embedding']),\n",
    "            }\n",
    "        )\n",
    "        \n",
    "#         print(len(value_list))\n",
    "        \n",
    "        if len(value_list) >= 1000:\n",
    "            result = search_client.upload_documents(value_list)\n",
    "            print(f\"Uploaded {len(value_list)} payload\")\n",
    "            value_list = []\n",
    "    result = search_client.upload_documents(value_list)\n",
    "    print(f\"Uploaded {len(value_list)} payload\")\n",
    "    \n",
    "            \n",
    "            \n",
    "#     print('payload of size {}'.format(len(value_list)))\n",
    "\n",
    "    return value_list\n",
    "\n",
    "\n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "payload = batch_append_payload(df_chunks_embedding, search_client)\n",
    " \n",
    "# print(f\"Uploaded {len(payload)} payload\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Types 1: Pure Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSFT\n",
      "2\n",
      "23\n",
      "Microsoft FY23 Second Quarter Earnings Conference Call Brett Iversen, Satya Nadella, Amy Hood Tuesday, January 24, 2023 BRETT IVERSEN: Good afternoon and thank you for joining us today. On the call with me are Satya Nadella, chairman and chief executive officer, Amy Hood, chief financial officer, Alice Jolla, chief accounting officer, and Keith Dolliver, deputy general counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to \n"
     ]
    }
   ],
   "source": [
    "# Pure Vector Search\n",
    "query = \"Microsoft earnings call for year 2022 for Quarter 2\"  \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)\n",
    "vector = Vector(value=createEmbeddings(query), k=2, fields=\"Embedding\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vectors=[vector],\n",
    "#     select=[\"Ticker\", \"Quarter\", \"Year\"],\n",
    ")\n",
    "\n",
    "# results\n",
    "  \n",
    "for result in results: \n",
    "    print(result['Ticker'])\n",
    "    print(result['Quarter'])\n",
    "    print(result['Year'])\n",
    "    print(result['Chunk'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Types 2: Pure Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: MSFT\n",
      "Quarter: 1\n",
      "Year: 23\n",
      "Microsoft FY23 First Quarter Earnings Conference Call Brett Iversen, Satya Nadella, Amy Hood Tuesday, October 25, 2022 BRETT IVERSEN: Good afternoon and thank you for joining us today. On the call with me are Satya Nadella, chairman and chief executive officer, Amy Hood, chief financial officer, Alice Jolla, chief accounting officer, and Keith Dolliver, deputy general counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to \n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    filter=\"(Ticker eq 'MSFT') and (Year eq '23') and (Quarter eq '1') \",\n",
    ")  \n",
    "\n",
    "for result in results:\n",
    "    print(f\"Ticker: {result['Ticker']}\")\n",
    "    print(f\"Quarter: {result['Quarter']}\") \n",
    "    print(f\"Year: {result['Year']}\") \n",
    "    print(result['Chunk'])\n",
    "    print()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Types 3: Vector Search with filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: MSFT\n",
      "Quarter: 1\n",
      "Year: 23\n",
      "you're still seeing digitization. This is still the tailwind that helps customers solve problems. This is still the way to build growth and leverage in your business. And yet, you still want to optimize your workloads. You still want to run them the most efficiently so that you can then make room for new workload growth. We saw that across all segments. If there was one segment where I may have seen it a bit more, I would say, in the small or mid-sized segment of the market, that tends to be more through partner. We rely on partners to help customers do those same optimizations and prepare workloads. But it is that one point I know that people are focused on. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pure Vector Search with Filter\n",
    "query = \"What are the KPIs?\"  \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)  \n",
    "vector = Vector(value=createEmbeddings(query), k=5, fields=\"Embedding\")  \n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vectors=[vector],\n",
    "    filter=\"(Ticker eq 'MSFT') and (Year eq '23') and (Quarter eq '1') \",\n",
    "#     select=[\"Ticker\", \"Quarter\", \"Year\"],\n",
    ")  \n",
    "  \n",
    "for result in results:\n",
    "    print(f\"Ticker: {result['Ticker']}\")\n",
    "    print(f\"Quarter: {result['Quarter']}\") \n",
    "    print(f\"Year: {result['Year']}\") \n",
    "    print(result['Chunk'])\n",
    "    print()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Types 4: Hybrid Search with filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: MSFT\n",
      "Quarter: 1\n",
      "Year: 23\n",
      "AMY HOOD: Thanks, Keith, and I do appreciate you asking about that one point, because I do know it is a point of focus every quarter. And what I would say is there is some inherent volatility to that number. A point here or there, and you've heard me say it when we've been a point better, and you've heard me say it when we've been a point worse. And I want to focus mostly on what and how we see the number, which is that it is still a very large growth rate with growth across all segments and with growth across all geos. That was, to the question, generally in line with where we expected. And what we did see through the quarter is a real focus both by customers, but also by our sales and customer success teams on \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pure Vector Search with Filter\n",
    "query = \"What are the KPIs?\"  \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)  \n",
    "vector = Vector(value=createEmbeddings(query), k=5, fields=\"Embedding\")  \n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vectors=[vector],\n",
    "    filter=\"(Ticker eq 'MSFT') and (Year eq '23') and (Quarter eq '1') \",\n",
    "#     select=[\"Ticker\", \"Quarter\", \"Year\"],\n",
    "    top = 3\n",
    ")  \n",
    "  \n",
    "for result in results:\n",
    "    print(f\"Ticker: {result['Ticker']}\")\n",
    "    print(f\"Quarter: {result['Quarter']}\") \n",
    "    print(f\"Year: {result['Year']}\") \n",
    "    print(result['Chunk'])\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "nanogpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
