{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Prompts Chains and Retrieval Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load configs for database, Azure OpenAI, and other resources as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "# specify the name of the .env file name \n",
    "env_name = \"llm_pgvector.env\" # change to your own .env file name\n",
    "config = dotenv_values(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the same filter_id1_name and filter_id2_name in previous notebooks. \n",
    "filter_id1_name = \"\"  \n",
    "filter_id2_name = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Flex Postgres (PG)  for retrievals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import pool\n",
    "from psycopg2 import Error\n",
    "\n",
    "host = config[\"HOST\"]\n",
    "dbname = config[\"DBNAME\"] \n",
    "user = config[\"USER\"] \n",
    "password = config[\"PASSWORD\"] \n",
    "sslmode = config[\"SSLMODE\"] \n",
    "\n",
    "# Build a connection string from the variables\n",
    "conn_string = \"host={0} user={1} dbname={2} password={3} sslmode={4}\".format(host, user, dbname, password, sslmode)\n",
    "\n",
    "postgreSQL_pool = psycopg2.pool.SimpleConnectionPool(1, 20,conn_string)\n",
    "if (postgreSQL_pool):\n",
    "    print(\"Connection pool created successfully\")\n",
    "\n",
    "# Use getconn() to get a connection from the connection pool\n",
    "connection = postgreSQL_pool.getconn()\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use pgvector, we need to first create the vector extension as described in this [link](https://learn.microsoft.com/en-us/azure/postgresql/flexible-server/how-to-use-pgvector) and shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a cursor to perform database operations\n",
    "# This is likely in case extension isn't already created from portal.\n",
    "cursor = connection.cursor()\n",
    "\n",
    "try:\n",
    "    # Start a new transaction\n",
    "    cursor.execute(\"BEGIN;\")\n",
    "\n",
    "    # Previous transaction statements\n",
    "    # ...\n",
    "\n",
    "    # Check if the extension already exists\n",
    "    extension_query = \"SELECT * FROM pg_extension WHERE extname = 'vector';\"\n",
    "    cursor.execute(extension_query)\n",
    "    extension_exists = cursor.fetchone()\n",
    "\n",
    "    if not extension_exists:\n",
    "        # Extension does not exist, create it\n",
    "        create_extension_query = \"CREATE EXTENSION vector;\"\n",
    "        cursor.execute(create_extension_query)\n",
    "        connection.commit()\n",
    "    else:\n",
    "        # Extension already exists, pass through\n",
    "        pass\n",
    "\n",
    "    # Commit the transaction\n",
    "    cursor.execute(\"COMMIT;\")\n",
    "except Exception as e:\n",
    "    # An error occurred, rollback the transaction\n",
    "    cursor.execute(\"ROLLBACK;\")\n",
    "    raise e\n",
    "finally:\n",
    "    # Close the cursor\n",
    "    cursor.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the total number of items based on filter_id1_name and Chunk Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already established a connection and have a cursor object\n",
    "\n",
    "# Rollback the current transaction\n",
    "connection.rollback()\n",
    "cursor = connection.cursor()\n",
    "# Execute the SELECT statement\n",
    "table_name1 = filter_id1_name\n",
    "table_name2 = 'ChunksEmbedding'\n",
    "try:\n",
    "    cursor.execute(f\"SELECT count(Id) FROM {table_name1};\")\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        print(f\"Number of items: {row}\")\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error executing SELECT statement: {e}\")\n",
    "    \n",
    "try:\n",
    "    cursor.execute(f\"SELECT embedding FROM {table_name2} limit 5;\")\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        print(f\"Items ID: {row}\")\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error executing SELECT statement: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for question embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "openai.api_type = config[\"OPENAI_API_TYPE\"] \n",
    "openai.api_key = config['OPENAI_API_KEY']\n",
    "openai.api_base = config['OPENAI_API_BASE'] \n",
    "openai.api_version = config['OPENAI_API_VERSION'] \n",
    "\n",
    "\n",
    "def createEmbeddings(text):\n",
    "    response = openai.Embedding.create(input=text , engine=config[\"OPENAI_DEPLOYMENT_EMBEDDING\"])\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Asks a Question \n",
    "In this step, the code will convert the user's question to an embedding and then retieve the top K document chunks based on the users' question using the similarity. Please note that other similarity metrics can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userQuestion = \"\"\n",
    "filter_id1_val = \"\"\n",
    "retrieve_k = 3 # for retrieving the top k reviews from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for the question and retrieve the top k document chunks\n",
    "questionEmbedding = createEmbeddings(userQuestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Search\n",
    "In this case, we will first filter based on id range, and then do similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "connection = psycopg2.connect(conn_string)\n",
    "# Create a cursor after the connection\n",
    "# Register 'pgvector' type for the 'embedding' column\n",
    "register_vector(connection)\n",
    "cursor = connection.cursor()\n",
    "filter_id1_name = 'abcd'\n",
    "table_name1 = filter_id1_name\n",
    "table_name2 = 'ChunksEmbedding'\n",
    "select_docid_query = f\"SELECT DocId FROM {table_name1} WHERE filter_id1_name = '{filter_id1_val}'\"\n",
    "cursor.execute(select_docid_query)\n",
    "doc_id = cursor.fetchone()[0]\n",
    "select_query = f\"SELECT Id FROM {table_name2} where DocId = '{doc_id}' ORDER BY embedding <-> %s LIMIT {retrieve_k}\"\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(select_query, (np.array(questionEmbedding),))\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the top k ids to retrieve the actual text from the database \n",
    "top_ids = []\n",
    "for i in range(len(results)):\n",
    "    top_ids.append(int(results[i][0]))\n",
    "\n",
    "print(top_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve text from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already established a connection and have a cursor object\n",
    "\n",
    "# Rollback the current transaction\n",
    "connection.rollback()\n",
    "\n",
    "format_ids = ', '.join(['%s'] * len(top_ids))\n",
    "\n",
    "sql = f\"SELECT CONCAT('PageNumber: ', PageNumber, ' ', 'LineNumber: ', LineNumber, ' ', 'Text: ', Chunk) AS concat FROM {table_name2} WHERE id IN ({format_ids})\"\n",
    "\n",
    "# Execute the SELECT statement\n",
    "try:\n",
    "    cursor.execute(sql, top_ids)    \n",
    "    top_rows = cursor.fetchall()\n",
    "    for row in top_rows:\n",
    "        print(row)\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error executing SELECT statement: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the context from the top_rows\n",
    "context = \"\"\n",
    "for row in top_rows:\n",
    "    context += row[0]\n",
    "    context += \"\\n\"\n",
    "    \n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provide answer to a user's question\n",
    "We use [langchain](https://python.langchain.com/en/latest/index.html) to construct chains and add prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "question_prompt_template = \"\"\"Use the following portion of the context document to find relevant text and answer the question in details. Extract PageNumber and LineNumber and show it in the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "If the answer is not found, say that answer is not available in the documentation.\"\"\"\n",
    "QUESTION_PROMPT = PromptTemplate(\n",
    "    template=question_prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define llm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://synapseml-openai.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2022-12-01\"\n",
    "os.environ[\"OPENAI_DEPLOYMENT_NAME\"] = \"text-davinci-003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import AzureOpenAI\n",
    "llm= AzureOpenAI(deployment_name=config[\"OPENAI_MODEL_COMPLETION\"], model_name=config[\"OPENAI_MODEL_EMBEDDING\"], temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "\n",
    "\n",
    "class TextFormatter(BaseLoader):\n",
    "    \"\"\"Load text files.\"\"\"\n",
    "\n",
    "    def __init__(self, text: str):\n",
    "        \"\"\"Initialize with file path.\"\"\"\n",
    "        self.text = text\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"Load from file path.\"\"\"\n",
    "        metadata = {\"source\": \"\"}\n",
    "        return [Document(page_content=self.text, metadata=metadata)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "loader = TextFormatter(context)\n",
    "# qa_document_chain.run(input_document=context, question=userQuestion)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=QUESTION_PROMPT)\n",
    "ans = chain({\"input_documents\": loader.load(), \"question\": userQuestion}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Navigate to the directory containing the CSV file (one level above the current directory)\n",
    "data_directory = os.path.abspath(os.path.join(current_directory, '..', 'ValidationSetOfQA'))\n",
    "\n",
    "# Construct the file path for your CSV file in the data_directory\n",
    "csv_file_path = os.path.join(data_directory, 'QnAValidationSet.csv')\n",
    "\n",
    "# Load the CSV file using pandas\n",
    "df = pd.read_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [filter_id1_name, filter_id2_name, 'Question', 'Answer', 'ReferenceText', 'PageNumber']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = df.copy()\n",
    "#df_eval.dropna(subset=[\"question\"] ,inplace=True)\n",
    "#df_eval.reset_index(drop=True, inplace=True)\n",
    "df_eval.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [item for pair in zip(list(df_eval['Question']), list(df_eval['Answer'])) for item in pair]\n",
    "keys = [str(i//2)+'a' if i%2==0 else str(i//2+1)+'q' for i in range(1,len(values)+2)]\n",
    "\n",
    "userQuestions = {keys[i]:values[i] for i in range(len(keys)-1)}\n",
    "filter_id1_vals = [item for item in list(df_eval[filter_id1_name]) for _ in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_id1_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT based question answering with type checking\n",
    "from langchain import PromptTemplate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a retrieve_k_chunk function to facilitate multiple query evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_k_chunk(retrieve_k, questionEmbedding,filter_id1_val):\n",
    "    connection = psycopg2.connect(conn_string)\n",
    "# Create a cursor after the connection\n",
    "# Register 'pgvector' type for the 'embedding' column\n",
    "    register_vector(connection)\n",
    "    cursor = connection.cursor()\n",
    "    print(\"filter_id1_name:\", filter_id1_name)\n",
    "    select_docid_query = f\"SELECT DocId FROM {table_name1} WHERE {filter_id1_name} = '{filter_id1_val}'\"\n",
    "    cursor.execute(select_docid_query)\n",
    "    doc_id = cursor.fetchone()[0]\n",
    "    print('docid:', doc_id)\n",
    "    select_query = f\"SELECT Id FROM {table_name2} where DocId = '{doc_id}' ORDER BY embedding <-> %s LIMIT {retrieve_k}\"\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(select_query, (np.array(questionEmbedding),))\n",
    "    results = cursor.fetchall()\n",
    "    top_ids = []\n",
    "    for i in range(len(results)):\n",
    "        top_ids.append(int(results[i][0]))\n",
    "\n",
    "    # Rollback the current transaction\n",
    "    connection.rollback()\n",
    "\n",
    "    format_ids = ', '.join(['%s'] * len(top_ids))\n",
    "\n",
    "    sql = f\"SELECT CONCAT('PageNumber: ', PageNumber, ' ', 'LineNumber: ', LineNumber, ' ', 'Text: ', Chunk) AS concat FROM {table_name2} WHERE id IN ({format_ids})\"\n",
    "\n",
    "    # Execute the SELECT statement\n",
    "    try:\n",
    "        cursor.execute(sql, top_ids)    \n",
    "        top_rows = cursor.fetchall()\n",
    "    except (Exception, Error) as e:\n",
    "        print(f\"Error executing SELECT statement: {e}\")\n",
    "    finally:\n",
    "        cursor.close()\n",
    "    return top_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userQuestions.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_questions_answers():\n",
    "    \"\"\"\n",
    "    Collection of user questions with known answers.\n",
    "    \"\"\"\n",
    "\n",
    "    Q = []\n",
    "    A = []\n",
    "    Agpt = []\n",
    "    i = 0\n",
    "    for key, value in userQuestions.items():\n",
    "        if \"q\" in key:\n",
    "            Q.append(value)\n",
    "            questionEmbedding = createEmbeddings(value)\n",
    "            output = retrieve_k_chunk(retrieve_k, questionEmbedding,filter_id1_vals[i] )\n",
    "            # create the context from the top_rows\n",
    "            context = \"\"\n",
    "            for row in top_rows:\n",
    "                context += row[0]\n",
    "                context += \"\\n\"\n",
    "            loader = TextFormatter(context)\n",
    "            chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=QUESTION_PROMPT)\n",
    "            ans = chain({\"input_documents\": loader.load(), \"question\": value}, return_only_outputs=True)\n",
    "            Agpt.append(ans['output_text'])\n",
    "            print(ans['output_text'])\n",
    "            i+=2\n",
    "        else:\n",
    "            A.append(value)\n",
    "\n",
    "    return  Q, A, Agpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, A, Agpt = get_user_questions_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarities(QA_results):\n",
    "    # compare cosine similarity between two vectors\n",
    "    cosine_similarities = []\n",
    "    for i in range(len(QA_results[0])):\n",
    "        emd1 = createEmbeddings(QA_results[0][i])\n",
    "        emd2 = createEmbeddings(QA_results[1][i])\n",
    "        cosine_similarity_val = cosine_similarity(\n",
    "            np.array(emd1).reshape(1, -1), np.array(emd2).reshape(1, -1)\n",
    "        )[0][0]\n",
    "        cosine_similarities.append(np.round(cosine_similarity_val, 2))\n",
    "    return cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QAres = [A, Agpt]\n",
    "scores = get_cosine_similarities(QAres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For elaborate experimentation and additional evaluations for page number, see Notebook Step_5_mlflow_experimentation.ipynb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flexenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
