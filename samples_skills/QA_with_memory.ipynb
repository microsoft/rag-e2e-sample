{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2469417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import openai\n",
    "from dotenv import dotenv_values\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "sys.path.append(\"..\") ## add directory above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1af107d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"../llm.env\" # change to use your own .env file\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "#Azure OpenAI\n",
    "openai.api_type = config[\"OPENAI_API_TYPE\"] #\"azure\"\n",
    "openai.api_key = config['OPENAI_API_KEY']\n",
    "openai.api_base = config['OPENAI_API_BASE']\n",
    "openai.api_version = config['OPENAI_API_VERSION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9c886c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = \"gpt-4-32k\"\n",
    "#engine = \"gpt-35-turbo\"\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=engine,\n",
    "    openai_api_base=openai.api_base,\n",
    "    openai_api_version=openai.api_version,\n",
    "    openai_api_key=openai.api_key,\n",
    "    openai_api_type = openai.api_type,\n",
    "    temperature=0.0, verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b0e6f8",
   "metadata": {},
   "source": [
    "## 1. Demonstrating conversation summary memory chain:\n",
    "This chain summarizes the previous user conversation and appends the summary to context for answering questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4886138d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: \n",
      "USSA is a space agency in county Y. It is a government agency responsible for the exploration and development of space.\n",
      "Question 2: \n",
      "Yes, I mentioned earlier about the USSA, a government space agency in county Y, responsible for space exploration and development.\n",
      "\n",
      "Context in question 2 does not contain any specific information regarding the \n",
      "       user question but still llm provides correct answer by using the memory of previous conversation\n"
     ]
    }
   ],
   "source": [
    "from chatbotSkills import qa_chain_ConversationSummaryMemory\n",
    "\n",
    "# Make a Question Answer chain function and pass \n",
    "prefix_template = \"\"\"\n",
    "        You are a chatbot having a conversation with a human. \n",
    "        Given the Context, Chat History, and a Human Query, \n",
    "        create a final answer. Don't hallucinate at all. If you don't have an answer, say \"I don't know\". \"\"\"\n",
    "\n",
    "qa_chain = qa_chain_ConversationSummaryMemory(llm, prefix_template=prefix_template, to_debug=False)\n",
    "\n",
    "## Question Answering\n",
    "\n",
    "#Question 1\n",
    "answer = qa_chain.run({\n",
    "        'context': \"USSA is a space agency in county Y. It is a government agency responsible for the exploration and development of space.\",\n",
    "        'human_input': \"What is USSA\" \n",
    "})\n",
    "\n",
    "print(\"Question 1: \")\n",
    "print(answer)\n",
    "\n",
    "# Question 2: \n",
    "answer = qa_chain.run({\n",
    "        'context': \"Zootopia is a 2016 American computer-animated buddy cop action comedy film produced by Walt Disney Animation Studios.\",\n",
    "        'human_input': \"Do you know about any space agency?\" \n",
    "}) \n",
    "\n",
    "print(\"Question 2: \")\n",
    "print(answer)\n",
    "print()\n",
    "print (\"\"\"Context in question 2 does not contain any specific information regarding the \n",
    "       user question but still llm provides correct answer by using the memory of previous conversation\"\"\")\n",
    "\n",
    "# print(qa_chain.memory) ## You can see the memory using this call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af592da",
   "metadata": {},
   "source": [
    "## 2. Demonstrating conversation buffer memory chain:\n",
    "This chain summarizes the previous user conversation and appends the summary to context for answering questions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69704b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: \n",
      "USSA is a space agency in county Y. It is a government agency responsible for the exploration and development of space.\n",
      "Question 2: \n",
      "Yes, I do. For instance, USSA is a space agency in county Y. It is a government agency responsible for the exploration and development of space.\n",
      "\n",
      "Context in question 2 does not contain any specific information regarding the \n",
      "       user question but still llm provides correct answer by using the memory of previous conversation\n"
     ]
    }
   ],
   "source": [
    "from chatbotSkills import qa_chain_ConversationBufferMemory\n",
    "\n",
    "# Make a Question Answer chain function and pass \n",
    "prefix_template = \"\"\"\n",
    "        You are a chatbot having a conversation with a human. \n",
    "        Given the Context, Chat History, and a Human Query, \n",
    "        create a final answer. Don't hallucinate at all. If you don't have an answer, say \"I don't know\". \"\"\"\n",
    "\n",
    "qa_chain = qa_chain_ConversationBufferMemory(llm, prefix_template=prefix_template, to_debug=False)\n",
    "\n",
    "## Question Answering\n",
    "\n",
    "#Question 1\n",
    "answer = qa_chain.run({\n",
    "        'context': \"USSA is a space agency in county Y. It is a government agency responsible for the exploration and development of space.\",\n",
    "        'human_input': \"What is USSA\" \n",
    "})\n",
    "\n",
    "print(\"Question 1: \")\n",
    "print(answer)\n",
    "\n",
    "# Question 2: \n",
    "answer = qa_chain.run({\n",
    "        'context': \"Zootopia is a 2016 American computer-animated buddy cop action comedy film produced by Walt Disney Animation Studios.\",\n",
    "        'human_input': \"Do you know about any space agency?\" \n",
    "}) \n",
    "\n",
    "print(\"Question 2: \")\n",
    "print(answer)\n",
    "print()\n",
    "print (\"\"\"Context in question 2 does not contain any specific information regarding the \n",
    "       user question but still llm provides correct answer by using the memory of previous conversation\"\"\")\n",
    "\n",
    "# print(qa_chain.memory) ## You can see the memory using this call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542530f",
   "metadata": {},
   "source": [
    "## 3. Demonstrating usre query based context summarization chain:\n",
    "Sometimes context can be large and don't fit in a prompt window. So, this chain summarizes context given user query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "539bc2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: \n",
      "USSA is a government space agency in county Y, responsible for the exploration and development of space.\n",
      "\n",
      "This llm extracts only relevant information from the context. \n"
     ]
    }
   ],
   "source": [
    "from chatbotSkills import user_query_based_context_summarization\n",
    "\n",
    "# Template \n",
    "prefix_template = \"\"\"\n",
    "        Write a concise summary of the context so that it includes the details related to the human query. \"\"\"\n",
    "\n",
    "context_summary_chain = user_query_based_context_summarization(llm, prefix_template=prefix_template, to_debug=False)\n",
    "\n",
    "context = \"\"\"\n",
    "            USSA is a space agency in county Y. It is a government agency responsible\n",
    "            for the exploration and development of space.\n",
    "            Zootopia is a 2016 American computer-animated buddy cop action comedy\n",
    "            film produced by Walt Disney Animation Studios.\n",
    "            \"\"\"\n",
    "\n",
    "#Question 1\n",
    "answer = context_summary_chain.run({\n",
    "        'context': context,\n",
    "        'human_input': \"What is USSA?\" \n",
    "})\n",
    "\n",
    "\n",
    "print(\"Question 1: \")\n",
    "print(answer)\n",
    "print()\n",
    "\n",
    "print (\"\"\"This llm extracts only relevant information from the context. \"\"\")\n",
    "\n",
    "# print(qa_chain.memory) ## You can see the memory using this call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d397d",
   "metadata": {},
   "source": [
    "## 3. Demonstrating combine_docs:\n",
    "Sometimes contexts retrieved from the database can be large and doesn't fit in a prompt. So, this code will extract relevant information from the context given the user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6b9e2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_token_count:  134\n",
      "output_token_count:  33\n",
      "output:  USSA stands for United Space Exploration Administration, which is county Y's premier governmental space agency responsible for the exploration, investigation, and advancement of the cosmic frontier.\n",
      "\n",
      "This demonstrates that the combine_docs function reduces the tokens for the input\n"
     ]
    }
   ],
   "source": [
    "from chatbotSkills import combine_docs, count_tokens\n",
    "\n",
    "context_1 = \"\"\"\n",
    "    The United Space Exploration Administration (USSA) stands as county Y's premier governmental space agency, \n",
    "    entrusted with the monumental task of spearheading the exploration, investigation, and advancement of the cosmic frontier.\n",
    "    With a dedicated cadre of brilliant scientists, intrepid astronauts, \n",
    "    and cutting-edge technology, USSA pioneers a path to unlock the mysteries of the universe and \n",
    "    harness its potential for the betterment of humanity. \n",
    "    \"\"\"\n",
    "context_2 = \"\"\"\n",
    "    Through audacious missions and visionary initiatives, \n",
    "    USSA propels the nation to new heights, ensuring that the celestial realm \n",
    "    becomes a beacon of knowledge, opportunity, and inspiration for generations to come.\n",
    "    \"\"\"\n",
    "\n",
    "context_list = [context_1, context_2]\n",
    "\n",
    "input_token_count = count_tokens(context_1+context_2, \"gpt-4-32k\")\n",
    "prefix_template = \"\"\"\n",
    "        Extract information from the context so that it includes the details related to the human query. \"\"\"\n",
    "user_query = \"What does USSA tands for?\" \n",
    "max_input_tokens = 100 ## For demonstration, we are assuming that max tokenfor input context should not exceed 100\n",
    "\n",
    "output = combine_docs(context_list, llm, to_debug=False, max_tokens=max_input_tokens, \n",
    "                      user_query=user_query, prefix_template=prefix_template)\n",
    "\n",
    "output_token_count = count_tokens(output, \"gpt-4-32k\")\n",
    "print(\"input_token_count: \", input_token_count)\n",
    "print(\"output_token_count: \", output_token_count)\n",
    "\n",
    "print(\"output: \", output)\n",
    "print()\n",
    "print(\"\"\"This demonstrates that the combine_docs function reduces the tokens for the input\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a003e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
